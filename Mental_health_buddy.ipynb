{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMnzOHLXGmmH4kJLJoBDYFi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Venkata1345/Mental_health_buddy/blob/main/Mental_health_buddy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoyzjmcUgQ0C"
      },
      "outputs": [],
      "source": [
        "pip install \"unsloth[colab-new]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"transformers\" \"peft\" \"accelerate\" \"bitsandbytes\" \"datasets\""
      ],
      "metadata": {
        "id": "NnzKR5ENg6Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "model_name=\"unsloth/Qwen3-30B-A3B-bnb-4bit\"\n",
        "\n",
        "model, tokenizer= FastLanguageModel.from_pretrained(model_name=model_name, max_seq_length=2048, dtype=None, load_in_4bit=True)"
      ],
      "metadata": {
        "id": "D2gbMHwzhNXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure LoRA parameters\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = True,\n",
        ")"
      ],
      "metadata": {
        "id": "_Scye5vui8Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Define your tokenizer and EOS_TOKEN before this\n",
        "# tokenizer = ...\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "# NEW formatting function\n",
        "def formatting_prompts_func(examples):\n",
        "    contexts = examples['Context']\n",
        "    responses = examples['Response']\n",
        "    texts = []\n",
        "    for context, response in zip(contexts, responses):\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": context},\n",
        "            {\"role\": \"assistant\", \"content\": response}\n",
        "        ]\n",
        "        formatted_text = tokenizer.apply_chat_template(\n",
        "            messages, tokenize = False, add_generation_prompt = False\n",
        "        )\n",
        "        texts.append(formatted_text + EOS_TOKEN)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "# Load and map the dataset\n",
        "dataset = load_dataset(\"Amod/mental_health_counseling_conversations\", split = \"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
        "\n",
        "# Your dataset is now correctly formatted and ready for training.\n",
        "print(\"Formatting successful!\")"
      ],
      "metadata": {
        "id": "-RCCozUFnUOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = 2048,\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 10,\n",
        "        max_steps = 60, # Set to a specific number of steps for a quick test run\n",
        "        num_train_epochs = 3, # Or train for a number of epochs\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 42,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Start training!\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "xSKWdc5FpPru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "B0WB1m8xN933"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Push just the LoRA adapters (most common)\n",
        "model.push_to_hub(\"Abhishek4545/qwen3-30b-mental-health-buddy-lora\")\n",
        "tokenizer.push_to_hub(\"Abhishek4545/qwen3-30b-mental-health-buddy-lora\")\n",
        "\n",
        "# Or, if you merged the model first:\n",
        "# merged_model.push_to_hub(\"your_hf_username/qwen3-8b-mental-health-buddy-merged\")\n",
        "# tokenizer.push_to_hub(\"your_hf_username/qwen3-8b-mental-health-buddy-merged\")"
      ],
      "metadata": {
        "id": "b5kC93jeOFE2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}